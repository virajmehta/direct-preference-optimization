python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=sft exp_name=jeopardy_llama7b_further_epinet gradient_accumulation_steps=2 batch_size=128 eval_batch_size=32 sample_during_eval=True pretrain=False have_llm_dropout=False epinet=True eval_every=2048 model.archive=/home/scratch/vdas/dpo/jeopardy_llama_epinet_2023-09-03_18-23-49_909777/LATEST/policy.pt max_train_examples=30000
python -u train_qlora.py model=llama7b datasets=[hh] loss=sft exp_name=hh_llama7b_further_epinet gradient_accumulation_steps=2 batch_size=128 eval_batch_size=32 sample_during_eval=True pretrain=False have_llm_dropout=True eval_every=2048 model.archive=/home/scratch/vdas/dpo/hh_llama_epinet_2023-09-03_09-15-29_553208/LATEST/policy.pt max_train_examples=30000
python -u train_qlora.py model=llama7b datasets=[shp] loss=sft exp_name=shp_llama7b_further_epinet gradient_accumulation_steps=2 batch_size=128 eval_batch_size=32 sample_during_eval=True pretrain=False have_llm_dropout=False epinet=True eval_every=2048 model.archive=/home/scratch/vdas/dpo/shp_llama_epinet_2023-09-02_20-23-22_780655/LATEST/policy.pt n_epochs=2 max_train_examples=30000