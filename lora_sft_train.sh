# python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=sft exp_name=jeopardy_llama7b_sft gradient_accumulation_steps=2 batch_size=32 eval_batch_size=16 sample_during_eval=True  # model.fsdp_policy_mp=bfloat16 trainer=FSDPTrainer  
python -u train_qlora.py model=llama7b datasets=[hh] loss=sft exp_name=hh_llama7b_sft gradient_accumulation_steps=2 batch_size=32 eval_batch_size=16  sample_during_eval=True epinet=True # model.fsdp_policy_mp=bfloat16 trainer=FSDPTrainer
# python -u train_qlora.py model=llama7b datasets=[shp] loss=sft exp_name=shp_llama7b_sft gradient_accumulation_steps=2 batch_size=32 eval_batch_size=16 sample_during_eval=True # model.fsdp_policy_mp=bfloat16 trainer=FSDPTrainer 
