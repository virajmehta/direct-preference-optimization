python -u train_qlora_jeopardy.py model=llama7b datasets=[jeopardy] loss=sft model.archive=/home/scratch/vdas/dpo/jeopardy_sft_dropout_2023-09-05_00-48-07_633053/LATEST/policy.pt exp_name=jeopardy_llama7b_further gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 sample_during_eval=True active=False pretrain=False have_llm_dropout=True max_train_examples=30000 seed=3
python -u train_qlora_jeopardy.py model=llama7b datasets=[jeopardy] loss=sft model.archive=/home/scratch/vdas/dpo/jeopardy_sft_dropout_2023-09-05_00-48-07_633053/LATEST/policy.pt exp_name=jeopardy_llama7b_further gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 sample_during_eval=True active=False pretrain=False have_llm_dropout=True max_train_examples=30000 seed=4

python -u train_qlora_jeopardy.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 model.archive=/home/scratch/vdas/dpo/jeopardy_sft_dropout_2023-09-05_00-48-07_633053/LATEST/policy.pt exp_name=jeopardy_llama_dropout_quantized_dpo_noactive gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 sample_during_eval=True active=False pretrain=False have_llm_dropout=True max_train_examples=30000 seed=3
python -u train_qlora_jeopardy.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 model.archive=/home/scratch/vdas/dpo/jeopardy_sft_dropout_2023-09-05_00-48-07_633053/LATEST/policy.pt exp_name=jeopardy_llama_dropout_quantized_dpo_noactive gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 sample_during_eval=True active=False pretrain=False have_llm_dropout=True max_train_examples=30000 seed=4