python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 active_beta=4.0 model.archive=/home/viraj/dpo/jeopardy/LATEST/policy.pt exp_name=jeopardy_active_llama7b_dropout gradient_accumulation_steps=6 batch_size=32 eval_batch_size=32 sample_during_eval=True active=True pretrain=False have_llm_dropout=True max_train_examples=30000 seed=0
python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 active_beta=4.0 model.archive=/home/viraj/dpo/jeopardy/LATEST/policy.pt exp_name=jeopardy_active_llama7b_dropout gradient_accumulation_steps=6 batch_size=32 eval_batch_size=32 sample_during_eval=True active=True pretrain=False have_llm_dropout=True max_train_examples=30000 seed=1
python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 active_beta=4.0 model.archive=/home/viraj/dpo/jeopardy/LATEST/policy.pt exp_name=jeopardy_active_llama7b_dropout gradient_accumulation_steps=6 batch_size=32 eval_batch_size=32 sample_during_eval=True active=True pretrain=False have_llm_dropout=True max_train_examples=30000 seed=2
python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 active_beta=4.0 model.archive=/home/viraj/dpo/jeopardy/LATEST/policy.pt exp_name=jeopardy_active_llama7b_dropout gradient_accumulation_steps=6 batch_size=32 eval_batch_size=32 sample_during_eval=True active=True pretrain=False have_llm_dropout=True max_train_examples=30000 seed=3
python -u train_qlora.py model=llama7b datasets=[jeopardy] loss=dpo loss.beta=0.1 active_beta=4.0 model.archive=/home/viraj/dpo/jeopardy/LATEST/policy.pt exp_name=jeopardy_active_llama7b_dropout gradient_accumulation_steps=6 batch_size=32 eval_batch_size=32 sample_during_eval=True active=True pretrain=False have_llm_dropout=True max_train_examples=30000 seed=4