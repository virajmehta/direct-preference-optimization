python -u train.py model=pythia28 datasets=[hh] loss=dpo loss.beta=0.1 model.archive=trained_models/hh_sft_pythia28/policy.pt exp_name=hh_dpo_pythia28 gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 trainer=FSDPTrainer sample_during_eval=false
python -u train.py model=pythia28 datasets=[shp] loss=dpo loss.beta=0.1 model.archive=trained_models/shp_sft_pythia28/policy.pt exp_name=shp_dpo_pythia28 gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 trainer=FSDPTrainer sample_during_eval=false
# python -u train.py model=pythia28 datasets=[anthropic] loss=dpo loss.beta=0.1 model.archive=trained_models/anthropic_sft_pythia28/policy.pt exp_name=anthropic_dpo_pythia28 gradient_accumulation_steps=4 batch_size=32 eval_batch_size=32 trainer=FSDPTrainer sample_during_eval=false
